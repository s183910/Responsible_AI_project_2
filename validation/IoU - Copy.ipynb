{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth for fuglene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n9286 158.Bay_breasted_Warbler/Bay_Breasted_Warbler_0011_159736.jpg\\n9286 65.0 92.0 353.0 213.0\\n\\n9273 158.Bay_breasted_Warbler/Bay_Breasted_Warbler_0100_797142.jpg\\n9273 202.0 116.0 256.0 180.0\\n\\n10840 184.Louisiana_Waterthrush/Louisiana_Waterthrush_0022_177397.jpg\\n10840 85.0 85.0 253.0 176.0\\n\\n3344 058.Pigeon_Guillemot/Pigeon_Guillemot_0043_39861.jpg\\n3344 75.0 61.0 244.0 278.0\\n\\n3350 058.Pigeon_Guillemot/Pigeon_Guillemot_0109_39872.jpg\\n3350 71.0 15.0 139.0 181.0\\n\\n11068 188.Pileated_Woodpecker/Pileated_Woodpecker_0027_179956.jpg\\n11068 76.0 31.0 320.0 467.0\\n\\n7446 127.Savannah_Sparrow/Savannah_Sparrow_0093_118267.jpg\\n7446 163.0 95.0 133.0 278.0\\n\\n10531 179.Tennessee_Warbler/Tennessee_Warbler_0022_174799.jpg\\n10531 78.0 119.0 246.0 153.0\\n\\n10512 179.Tennessee_Warbler/Tennessee_Warbler_0067_174999.jpg\\n10512 122.0 127.0 255.0 217.0\\n\\n11691 199.Winter_Wren/Winter_Wren_0113_189558.jpg\\n11691 185.0 32.0 208.0 258.0\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "9286 158.Bay_breasted_Warbler/Bay_Breasted_Warbler_0011_159736.jpg\n",
    "9286 65.0 92.0 353.0 213.0\n",
    "\n",
    "9273 158.Bay_breasted_Warbler/Bay_Breasted_Warbler_0100_797142.jpg\n",
    "9273 202.0 116.0 256.0 180.0\n",
    "\n",
    "10840 184.Louisiana_Waterthrush/Louisiana_Waterthrush_0022_177397.jpg\n",
    "10840 85.0 85.0 253.0 176.0\n",
    "\n",
    "3344 058.Pigeon_Guillemot/Pigeon_Guillemot_0043_39861.jpg\n",
    "3344 75.0 61.0 244.0 278.0\n",
    "\n",
    "3350 058.Pigeon_Guillemot/Pigeon_Guillemot_0109_39872.jpg\n",
    "3350 71.0 15.0 139.0 181.0\n",
    "\n",
    "11068 188.Pileated_Woodpecker/Pileated_Woodpecker_0027_179956.jpg\n",
    "11068 76.0 31.0 320.0 467.0\n",
    "\n",
    "7446 127.Savannah_Sparrow/Savannah_Sparrow_0093_118267.jpg\n",
    "7446 163.0 95.0 133.0 278.0\n",
    "\n",
    "10531 179.Tennessee_Warbler/Tennessee_Warbler_0022_174799.jpg\n",
    "10531 78.0 119.0 246.0 153.0\n",
    "\n",
    "10512 179.Tennessee_Warbler/Tennessee_Warbler_0067_174999.jpg\n",
    "10512 122.0 127.0 255.0 217.0\n",
    "\n",
    "11691 199.Winter_Wren/Winter_Wren_0113_189558.jpg\n",
    "11691 185.0 32.0 208.0 258.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katrine_bay/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, resnet34\n",
    "import matplotlib.pyplot as plt\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from torchcam.methods import SmoothGradCAMpp, LayerCAM\n",
    "\n",
    "# https://frgfm.github.io/torch-cam/methods.html#torchcam.methods.SmoothGradCAMpp\n",
    "# I believe this is smoothgrad from the lecture\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "## import the necessary packages\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import cv2  # pip install opencv-python\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bb = pd.read_csv('bounding_boxes.txt', sep=' ', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>325</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>30</td>\n",
       "      <td>153</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>112</td>\n",
       "      <td>388</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>90</td>\n",
       "      <td>255</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>134</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11783</th>\n",
       "      <td>11784</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>354</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11784</th>\n",
       "      <td>11785</td>\n",
       "      <td>157</td>\n",
       "      <td>62</td>\n",
       "      <td>184</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11785</th>\n",
       "      <td>11786</td>\n",
       "      <td>190</td>\n",
       "      <td>102</td>\n",
       "      <td>198</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11786</th>\n",
       "      <td>11787</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>408</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787</th>\n",
       "      <td>11788</td>\n",
       "      <td>20</td>\n",
       "      <td>113</td>\n",
       "      <td>177</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11788 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1    2    3    4\n",
       "0          1   60   27  325  304\n",
       "1          2  139   30  153  264\n",
       "2          3   14  112  388  186\n",
       "3          4  112   90  255  242\n",
       "4          5   70   50  134  303\n",
       "...      ...  ...  ...  ...  ...\n",
       "11783  11784   89   95  354  250\n",
       "11784  11785  157   62  184  219\n",
       "11785  11786  190  102  198  202\n",
       "11786  11787    3   20  408  307\n",
       "11787  11788   20  113  177  263\n",
       "\n",
       "[11788 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make bb integers\n",
    "\n",
    "bb = bb.astype(int)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'andreascsv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pp \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mandreascsv.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m pp \u001b[39m=\u001b[39m pp\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'andreascsv.csv'"
     ]
    }
   ],
   "source": [
    "pp = pd.read_csv('andreascsv.csv', sep=' ', header=None)\n",
    "pp = pp.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get just one value from the row :\n",
    "\n",
    "x_min = bb[bb[0]==9286].values[0][1]\n",
    "x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1,     2,     3, ..., 11786, 11787, 11788])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_ids = bb[0].unique()\n",
    "list_of_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# set up model, pretrained on imagenet\n",
    "model = resnet34(weights=\"DEFAULT\").eval()\n",
    "# don't really know what this does (especially the normalize thing - were do the variables come from?\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# to visualize the images in same format\n",
    "preprocess_visualise = transforms.Compose(\n",
    "    [transforms.Resize(299), transforms.CenterCrop(299), transforms.ToTensor()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loading the test images\n",
    "imgs = glob.glob(\"handful_of_images/*.jpg\")\n",
    "len(imgs)\n",
    "\n",
    "cam_extractor = SmoothGradCAMpp(model, target_layer=\"layer4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_heat_map(fileNames, overlay):\n",
    "    # getting the saliency maps on the images\n",
    "    fig, ax = plt.subplots(2, 5, tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    for i, img in enumerate(fileNames):\n",
    "        input_image = Image.open(img)\n",
    "        cropped_img = preprocess_visualise(input_image)\n",
    "\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "        out = model(input_batch)\n",
    "        cams = cam_extractor(out.squeeze(0).argmax().item(), out)\n",
    "\n",
    "        if overlay:\n",
    "            result = overlay_mask(\n",
    "                to_pil_image(cropped_img), to_pil_image(cams[0].squeeze(0), mode=\"F\"), alpha=0.5\n",
    "            )\n",
    "            ax[i].imshow(result)\n",
    "            ax[i].set_axis_off()\n",
    "        else:\n",
    "            ax[i].imshow(cams[0].squeeze(0))\n",
    "            ax[i].set_axis_off()\n",
    "\n",
    "    plt.show()\n",
    "get_heat_map(imgs, True)\n",
    "\n",
    "cam_extractor.remove_hooks()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU on saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Detection = namedtuple(\"Detection\", [\"image_path\", \"gt\", \"pred\"])\n",
    "\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def IoU_saliency(fileNames, id, overlay, model_name):\n",
    "    # ax = ax.ravel()\n",
    "    for i, img in enumerate(fileNames):\n",
    "        input_image = Image.open(img)\n",
    "        cropped_img = preprocess_visualise(input_image)\n",
    "\n",
    "        input_tensor = preprocess(input_image)\n",
    "        input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "        out = model(input_batch)\n",
    "        cams = cam_extractor(out.squeeze(0).argmax().item(), out)\n",
    "\n",
    "        val = []\n",
    "        for i in range(0, cams[0].squeeze(0).shape[0]):\n",
    "            index, value = max(enumerate(cams[0].squeeze(0)[i]), key=operator.itemgetter(1))\n",
    "            val.append(value)\n",
    "\n",
    "        y_index, y_value = max(enumerate(val), key=operator.itemgetter(1))\n",
    "        x_index, x_value = max(enumerate(cams[0].squeeze(0)[y_index]), key=operator.itemgetter(1))\n",
    "\n",
    "        imz = Image.open(img).convert(\"L\")\n",
    "        wid, hei = imz.size\n",
    "\n",
    "        cms = cams[0].squeeze(0).shape[0]\n",
    "\n",
    "        x_ = wid // cms\n",
    "        y_ = hei // cms\n",
    "        x = (x_index) * x_\n",
    "        y = (y_index) * y_\n",
    "\n",
    "        if model_name == 'saliency':\n",
    "            examples = [\n",
    "                Detection(\n",
    "                    fileNames[i], # TODO her er det lige hardcoded hvilket id det skal være - indsæt id som en parameter\n",
    "                    [bb[bb[0]==9286].values[0][1], bb[bb[0]==9286].values[0][2], bb[bb[0]==9286].values[0][1] + bb[bb[0]==9286].values[0][3] , bb[bb[0]==9286].values[0][2] + bb[bb[0]==9286].values[0][4] ],\n",
    "                    [(x - (wid // cms)), (y - (hei // cms)), (x + (wid // cms)), (y + (hei // cms))],\n",
    "                )\n",
    "            ]\n",
    "        elif model_name == 'proto':\n",
    "            examples = [\n",
    "                Detection(\n",
    "                    fileNames[i], # TODO her er det lige hardcoded hvilket id det skal være - indsæt id som en parameter\n",
    "                    [bb[bb[0]==9286].values[0][1], bb[bb[0]==9286].values[0][2], bb[bb[0]==9286].values[0][1] + bb[bb[0]==9286].values[0][3] , bb[bb[0]==9286].values[0][2] + bb[bb[0]==9286].values[0][4] ],\n",
    "                    [pp[pp[0]==9286].values[0][1], pp[pp[0]==9286].values[0][2], pp[pp[0]==9286].values[0][3], pp[pp[0]==9286].values[0][4]],\n",
    "                )\n",
    "            ]\n",
    "        \n",
    "        return examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m         cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m, image)\n\u001b[1;32m     28\u001b[0m         cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m IoU_saliency_display(imgs, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     32\u001b[0m cam_extractor\u001b[39m.\u001b[39mremove_hooks()\n",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m, in \u001b[0;36mIoU_saliency_display\u001b[0;34m(fileNames, id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mIoU_saliency_display\u001b[39m(fileNames, \u001b[39mid\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     examples \u001b[39m=\u001b[39m IoU_saliency(imgs, \u001b[39m1\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39msaliency\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# loop over the example detections\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m detection \u001b[39min\u001b[39;00m examples:\n\u001b[1;32m      6\u001b[0m         \u001b[39m# load the image\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m, in \u001b[0;36mIoU_saliency\u001b[0;34m(fileNames, id, overlay, model_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m y \u001b[39m=\u001b[39m (y_index) \u001b[39m*\u001b[39m y_\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msaliency\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     32\u001b[0m     examples \u001b[39m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m         Detection(\n\u001b[0;32m---> 34\u001b[0m             fileNames[i], \u001b[39m# TODO her er det lige hardcoded hvilket id det skal være - indsæt id som en parameter\u001b[39;00m\n\u001b[1;32m     35\u001b[0m             [bb[bb[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m9286\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m], bb[bb[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m9286\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m2\u001b[39m], bb[bb[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m9286\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m bb[bb[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m9286\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m3\u001b[39m] , bb[bb[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m9286\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m bb[bb[\u001b[39m0\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m9286\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m][\u001b[39m4\u001b[39m] ],\n\u001b[1;32m     36\u001b[0m             [(x \u001b[39m-\u001b[39m (wid \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m cms)), (y \u001b[39m-\u001b[39m (hei \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m cms)), (x \u001b[39m+\u001b[39m (wid \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m cms)), (y \u001b[39m+\u001b[39m (hei \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m cms))],\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     38\u001b[0m     ]\n\u001b[1;32m     39\u001b[0m \u001b[39melif\u001b[39;00m model_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mproto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     examples \u001b[39m=\u001b[39m [\n\u001b[1;32m     41\u001b[0m         Detection(\n\u001b[1;32m     42\u001b[0m             fileNames[i], \u001b[39m# TODO her er det lige hardcoded hvilket id det skal være - indsæt id som en parameter\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m     ]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "def IoU_saliency_display(fileNames, id):\n",
    "    examples = IoU_saliency(imgs, 9286, True, 'saliency')\n",
    "\n",
    "# loop over the example detections\n",
    "    for detection in examples:\n",
    "        # load the image\n",
    "        image = cv2.imread(detection.image_path)\n",
    "        # draw the ground-truth bounding box along with the predicted\n",
    "        # bounding box\n",
    "        cv2.rectangle(image, tuple(detection.gt[:2]), tuple(detection.gt[2:]), (0, 255, 0), 2)\n",
    "        cv2.rectangle(\n",
    "            image, tuple(detection.pred[:2]), tuple(detection.pred[2:]), (0, 0, 255), 2\n",
    "        )\n",
    "        # compute the intersection over union and display it\n",
    "        iou = bb_intersection_over_union(detection.gt, detection.pred)\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            \"IoU: {:.4f}\".format(iou),\n",
    "            (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.6,\n",
    "            (0, 255, 0),\n",
    "            2,\n",
    "        )\n",
    "        print(\"{}: {:.4f}\".format(detection.image_path, iou))\n",
    "        # show the output image\n",
    "        cv2.imshow('image', image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "\n",
    "IoU_saliency_display(imgs, 9286)\n",
    "cam_extractor.remove_hooks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "\n",
    "# lave en mappe med 1000 random billeder \n",
    "\n",
    "# lav visualisering på handful of image \n",
    "\n",
    "# lav mean over alle IoU fra saliency \n",
    "# lav mean over alle IoU fra proto\n",
    "\n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
